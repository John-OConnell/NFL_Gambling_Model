{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e06db600",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010\n",
      "crd\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 63\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team \u001b[38;5;129;01min\u001b[39;00m team_abbr:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# check to prevent overloading webpage with requests\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m20\u001b[39m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;66;03m# grab stats from specific team and year\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m         stats \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;66;03m# append to global stats array\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         all_stats\u001b[38;5;241m.\u001b[39mappend(stats)\n",
      "Cell \u001b[0;32mIn[3], line 24\u001b[0m, in \u001b[0;36mscrape_stats\u001b[0;34m(team, year)\u001b[0m\n\u001b[1;32m     21\u001b[0m soup \u001b[38;5;241m=\u001b[39m BeautifulSoup(r\u001b[38;5;241m.\u001b[39mcontent, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtml.parser\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# grab the team stats table from the team webpage\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m team_stats \u001b[38;5;241m=\u001b[39m \u001b[43msoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_all\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# grab the team conversions table from the team webpage\u001b[39;00m\n\u001b[1;32m     26\u001b[0m team_conv \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "from vardata import years, team_abbr, columns, teams\n",
    "\n",
    "url = 'https://www.pro-football-reference.com'\n",
    "\n",
    "# function to convert output a dataframe as a csv\n",
    "def df_to_csv(df, year):\n",
    "    exec(\"df.to_csv('stats_\" + year + \".csv')\")\n",
    "\n",
    "    \n",
    "def scrape_stats(team, year):\n",
    "    \n",
    "    print(team)\n",
    "    # use beautiful soup to return the html of the webpage\n",
    "    r = requests.get(url + '/teams/' + team + '/' + year + '.htm')\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    \n",
    "    # grab the team stats table from the team webpage\n",
    "    team_stats = soup.find_all('table')[0]\n",
    "    # grab the team conversions table from the team webpage\n",
    "    team_conv = soup.find_all('table')[2]\n",
    "\n",
    "    # Collect table rows from stats table\n",
    "    stat_rows = team_stats.findAll('tr')[2:4]\n",
    "    # Get stats from each row\n",
    "    stats = []\n",
    "    for i in range(len(stat_rows)):\n",
    "        stats.extend([float(col.getText()) for col in stat_rows[i].findAll('td')[:25]])\n",
    "\n",
    "    # Collect table rows from conversions table\n",
    "    conv_rows = team_conv.findAll('tr')[2:4]\n",
    "    # Get stats from each row\n",
    "    convs = []\n",
    "    for i in range(len(conv_rows)):\n",
    "        convs.extend([float(col.getText().strip('%')) for col in conv_rows[i].findAll('td')])\n",
    "   \n",
    "    # combine all stats\n",
    "    stats.extend(convs)\n",
    "    # insert the team abbrev at beggining of array\n",
    "    stats.insert(0, team)\n",
    "    # print(stats)\n",
    "    return stats\n",
    "    \n",
    "# ___________________________________\n",
    "\n",
    "#intialize num to act as counter and prevent over scrapping\n",
    "num = 1\n",
    "\n",
    "# loop through all years in vardata file\n",
    "for year in years:\n",
    "    all_stats = []\n",
    "    print(year)\n",
    "    # loop through each team listed in team abbrev list\n",
    "    for team in team_abbr:\n",
    "        # check to prevent overloading webpage with requests\n",
    "        if num < 20:\n",
    "            # grab stats from specific team and year\n",
    "            stats = scrape_stats(team, year)\n",
    "            # append to global stats array\n",
    "            all_stats.append(stats)\n",
    "            num += 1\n",
    "        else:\n",
    "            # grab stats from specific team and year\n",
    "            stats = scrape_stats(team, year)\n",
    "            # append to global stats array\n",
    "            all_stats.append(stats)\n",
    "            time.sleep(65)\n",
    "            num = 1\n",
    "    # convert global stats array to pandas dataframe\n",
    "    exec('ts_' + year + ' = pd.DataFrame(all_stats, columns = columns)')\n",
    "    # save dataframe to csv\n",
    "    exec('df_to_csv(ts_'+ year + ', year)')\n",
    "    # pause a random amount of time (from 1-5 mins) to prevent\n",
    "    # overloading webpage with requests\n",
    "    wait = random.randint(65, 120)\n",
    "    time.sleep(wait)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f57dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
